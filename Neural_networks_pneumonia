import numpy as np
from FuncionesMachineLearning import FunExam
from random import shuffle
from keras.models import Sequential
from keras.layers.core import Dense, Dropout
import warnings
warnings.filterwarnings('ignore')
f = FunExam()

csv_file_name = 'Data/stage_2_train_labels.csv'

dcm_file, Y_data = f.extraer_info(csv_file_name)

imgs_per_iter = 200
num_iters = int(np.count_nonzero(dcm_file)/imgs_per_iter)
idx = [i for i in range(imgs_per_iter)]
shuffle(idx)

gen_train = f.get_gen_train(dcm_file, Y_data, imgs_per_iter, num_iters, idx)
gen_test = f.get_gen_test(dcm_file, Y_data, imgs_per_iter, num_iters, idx)

num_classes = 2
num_neurons_input = 200  # no. neuronas primera capa
num_neurons_hidden_1 = 150  # no. neuronas primera capa oculta
num_neurons_hidden_2 = 100  # no. neuronas segunda capa oculta
num_neurons_hidden_3 = 50  # no. neuronas segunda capa oculta
prob_drop_out = 0.25   # 25% se desactiva por capa aleatoreamente para no sobreentrenar
img_width = 1024

num_epochs = 10

model = Sequential()

model.add(Dense(units=num_neurons_input,
                input_dim=img_width*img_width,
                activation='relu',
                use_bias=True,
                kernel_initializer='glorot_uniform'))

# Se añade un regularizador para evitar sobreajuste de curvas
model.add(Dropout(prob_drop_out))

# Se añade la primera capa oculta
model.add(Dense(units=num_neurons_hidden_1,
                activation='relu',
                use_bias=True,
                kernel_initializer='glorot_uniform'))

model.add(Dropout(prob_drop_out))

# Se añade la primera capa
model.add(Dense(units=num_neurons_hidden_2,
                activation='relu',
                use_bias=True,
                kernel_initializer='glorot_uniform'))

model.add(Dense(units=num_neurons_hidden_3,
                activation='relu',
                use_bias=True,
                kernel_initializer='glorot_uniform'))

model.add(Dense(units=num_classes, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

history = model.fit_generator(generator=gen_train,
                              steps_per_epoch=num_iters,
                              epochs=1,
                              verbose=1,
                              validation_steps=num_iters,
                              validation_data=gen_test)
